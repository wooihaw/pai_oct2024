{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Loading Built-in Dataset](#loading-builtin-data)\n",
    "* [Loading External Data](#loading-external-data)\n",
    "* [Statistical Summary and Class Breakdown](#statistical-summary)\n",
    "* [Dropping Rows with Missing Values](#dropping-rows)\n",
    "* [Data Imputation](#data-imputation)\n",
    "* [Categorical Data](#categorical-data)\n",
    "* [Min-max Scaling](#min-max-scaling)\n",
    "* [Standard Scaling](#standard-scaling)\n",
    "* [Robust Scaling](#robust-scaling)\n",
    "* [Feature Engineering](#feature-engineering)\n",
    "* [Univariate Selection](#univariate-selection)\n",
    "* [Recursive Feature Elimination](#recursive-feature-elimination)\n",
    "* [Hold-out Validation](#hold-out-validation)\n",
    "* [Cross Validation](#cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Built-in Dataset <a class=\"anchor\" id=\"loading-builtin-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target Names: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary module from scikit-learn\n",
    "from sklearn.datasets import load_iris\n",
    "# Load the Iris dataset\n",
    "dataset = load_iris()\n",
    "# Extract features and target\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "# Display feature names and target names\n",
    "print(\"Feature Names:\", dataset.feature_names)\n",
    "print(\"Target Names:\", dataset.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading External Data <a class=\"anchor\" id=\"loading-external-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9) (768, 8) (768,)\n"
     ]
    }
   ],
   "source": [
    "# Load data from CSV file\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=header)\n",
    "# Separate data into features and target\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "print(df.shape, X.shape, y.shape) # print the dimension of the dataframe, X & y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary and Class Breakdown <a class=\"anchor\" id=\"statistical-summary\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             preg        plas        pres        skin        test        mass  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
      "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
      "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
      "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "             pedi         age       class  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean     0.471876   33.240885    0.348958  \n",
      "std      0.331329   11.760232    0.476951  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243750   24.000000    0.000000  \n",
      "50%      0.372500   29.000000    0.000000  \n",
      "75%      0.626250   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n",
      "class\n",
      "0    500\n",
      "1    268\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print statistical summary and class breakdown\n",
    "from pandas import read_csv\n",
    "header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=header)\n",
    "print(df.describe()) # print the statistical summary of the data\n",
    "class_counts = df.groupby('class').size()\n",
    "print(class_counts) # print the class breakdown of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Rows with Missing Values <a class=\"anchor\" id=\"dropping-rows\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Height  Weight\n",
      "0  17.0     160    50.0\n",
      "1  23.0     172    68.0\n",
      "2   NaN     150    43.0\n",
      "3  38.0     165    52.0\n",
      "4  54.0     163    47.0\n",
      "5  67.0     158    49.0\n",
      "6  32.0     175     NaN\n",
      "Age       1\n",
      "Height    0\n",
      "Weight    1\n",
      "dtype: int64\n",
      "    Age  Height  Weight\n",
      "0  17.0     160    50.0\n",
      "1  23.0     172    68.0\n",
      "3  38.0     165    52.0\n",
      "4  54.0     163    47.0\n",
      "5  67.0     158    49.0\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values by dropping data samples with missing values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'Age': [17, 23, 0, 38, 54, 67, 32],\n",
    "                  'Height': [160, 172, 150, 165, 163, 158, 175],\n",
    "                  'Weight':[50, 68, 43, 52, 47, 49, 0]})\n",
    "df = df.replace({0: np.nan}) # replace missing value (0) with NaN\n",
    "print(df)\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna() # drop rows with NaN\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation <a class=\"anchor\" id=\"data-imputation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Height  Weight\n",
      "0  17.0     160    50.0\n",
      "1  23.0     172    68.0\n",
      "2  35.0     150    43.0\n",
      "3  38.0     165    52.0\n",
      "4  54.0     163    47.0\n",
      "5  67.0     158    49.0\n",
      "6  32.0     175    51.5\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values by imputing missing values with statistic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'Age': [17, 23, 0, 38, 54, 67, 32],\n",
    "                  'Height': [160, 172, 150, 165, 163, 158, 175],\n",
    "                  'Weight':[50, 68, 43, 52, 47, 49, 0]})\n",
    "df = df.replace({0: np.nan})\n",
    "df = df.fillna({'Age': df['Age'].median(), 'Weight': df['Weight'].mean()}) # replace NaN with statistics\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data <a class=\"anchor\" id=\"categorical-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  engine  review  maker_Honda  maker_Hyundai  maker_Perodua  \\\n",
      "0  2015     1.5       2        False          False          False   \n",
      "1  2017     1.8       3         True          False          False   \n",
      "2  2013     1.3       1        False          False           True   \n",
      "3  2018     1.6       2        False           True          False   \n",
      "4  2020     1.8       3        False          False          False   \n",
      "\n",
      "   maker_Toyota  \n",
      "0          True  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4          True  \n"
     ]
    }
   ],
   "source": [
    "# Handling categorical data\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'year':[2015, 2017, 2013, 2018, 2020], \n",
    "                  'maker':['Toyota', 'Honda', 'Perodua', 'Hyundai', 'Toyota'],\n",
    "                  'engine':[1.5, 1.8, 1.3, 1.6, 1.8],\n",
    "                  'review':['moderate', 'good', 'poor', 'moderate', 'good']})\n",
    "mapping = {'poor':1, 'moderate':2, 'good':3}\n",
    "df['review'] = df['review'].map(mapping) # encode ordinal data\n",
    "df = pd.get_dummies(df, columns=['maker']) # encode nominal data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-max Scaling <a class=\"anchor\" id=\"min-max-scaling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum=[0. 0. 0. 0. 0. 0. 0. 0.], maximum=[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Scale data (between 0 and 1)\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=header)\n",
    "# Separate into features and target\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(X)\n",
    "scaledX = scaler.transform(X)\n",
    "# Check min and max of all column\n",
    "print(f'minimum={np.min(scaledX, axis=0)}, maximum={np.max(scaledX, axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaling <a class=\"anchor\" id=\"standard-scaling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=[-6.47630098e-17 -9.25185854e-18  1.50342701e-17  1.00613962e-16\n",
      " -3.00685403e-17  2.59052039e-16  2.45174251e-16  1.93132547e-16], variance=[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=header)\n",
    "# Separate into features and target\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "scaler = StandardScaler()\n",
    "scaledX = scaler.fit_transform(X)\n",
    "# Check mean and standard deviation of all columns\n",
    "print(f'mean={np.mean(scaledX, axis=0)}, variance={np.var(scaledX, axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Scaling <a class=\"anchor\" id=\"robust-scaling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median=[0. 0. 0. 0. 0. 0. 0. 0.], IQR=[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Robust scaling (0 median, 1 IQR)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from pandas import read_csv\n",
    "header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=header)\n",
    "# Separate into features and target\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "scaler = RobustScaler()\n",
    "scaledX = scaler.fit_transform(X)\n",
    "# Check median and IQR of all columns\n",
    "q3, q1 = np.percentile(scaledX, [75 ,25], axis=0)\n",
    "print(f'median={np.median(scaledX, axis=0)}, IQR={q3-q1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering <a class=\"anchor\" id=\"feature-engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>new_feature1</th>\n",
       "      <th>new_feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "      <td>27.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class  new_feature1  \\\n",
       "0     6   148    72    35     0  33.6  0.627   50      1           220   \n",
       "1     1    85    66    29     0  26.6  0.351   31      0           151   \n",
       "2     8   183    64     0     0  23.3  0.672   32      1           247   \n",
       "3     1    89    66    23    94  28.1  0.167   21      0           155   \n",
       "4     0   137    40    35   168  43.1  2.288   33      1           177   \n",
       "\n",
       "   new_feature2  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2     27.833333  \n",
       "3     26.000000  \n",
       "4     31.500000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 2 new features\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=header)\n",
    "win_size = 3\n",
    "df['new_feature1'] = df['plas'] + df['pres'] # new feature 1\n",
    "df['new_feature2'] = df['mass'].rolling(win_size).mean() # new feature 2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Selection <a class=\"anchor\" id=\"univariate-selection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preg', 'plas', 'mass', 'age']\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection with Univariate Selection\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "# load data\n",
    "header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=header)\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "selector = SelectKBest(k=4)\n",
    "features = selector.fit_transform(X, y)\n",
    "selected = selector.get_support()\n",
    "# Show selected features\n",
    "print([header[i] for i, j in enumerate(selected) if j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination <a class=\"anchor\" id=\"recursive-feature-elimination\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plas', 'mass', 'pedi', 'age']\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection with RFE\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv(filename, names=header)\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "model = DecisionTreeClassifier()\n",
    "rfe = RFE(model, n_features_to_select=4)\n",
    "features = rfe.fit_transform(X, y)\n",
    "selected = rfe.get_support()\n",
    "# Show selected features\n",
    "print([header[i] for i, j in enumerate(selected) if j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-out Validation <a class=\"anchor\" id=\"hold-out-validation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.08%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using a train and a test set\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=header)\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.33, random_state=42)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "result = model.score(X_test, y_test)\n",
    "print(f\"Accuracy: {result:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation <a class=\"anchor\" id=\"cross-validation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.14% (1.92%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Cross Validation\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=header)\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "results = cross_val_score(model, X, y, cv=kfold)\n",
    "print(f\"Accuracy: {results.mean():.2%} ({results.std():.2%})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
